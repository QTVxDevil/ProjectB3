{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leloc/anaconda3/envs/facenet/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leloc/anaconda3/envs/facenet/lib/python3.11/site-packages/torch/cuda/__init__.py:141: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(image_size=160, margin=0, min_face_size=20,\n",
    "              thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((160, 160)),      # Resize ảnh về 160x160\n",
    "    transforms.ToTensor(),              # Chuyển ảnh thành tensor\n",
    "    transforms.Normalize(               # Chuẩn hóa giá trị pixel\n",
    "        mean=[0.5, 0.5, 0.5], \n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Danh sách ảnh: ['Data/ac84e587-7413-11ef-bf8a-e81f155e7428.jpg', 'Data/583448a4-aad6-11ef-b52d-c403a8a5aea1.jpg', 'Data/a7b937a7-7413-11ef-b46f-e81f155e7428.jpg', 'Data/ab16ce1e-7413-11ef-a7e1-e81f155e7428.jpg', 'Data/a6a96299-7413-11ef-8665-e81f155e7428.jpg']\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"Data\"\n",
    "image_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith(('.jpg', '.png'))]\n",
    "\n",
    "print(\"Danh sách ảnh:\", image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embedding(model, image_path, device):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    input_tensor = preprocess(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        embedding = model(input_tensor)\n",
    "    return embedding.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding của các ảnh tham chiếu đã được lưu.\n"
     ]
    }
   ],
   "source": [
    "embeddings = {}\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(('.jpg', '.png')):  # Chỉ lấy ảnh có đuôi .jpg hoặc .png\n",
    "        # Tải ảnh và tiền xử lý\n",
    "        image_path = os.path.join(folder_path, file_name)\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        input_tensor = preprocess(image).unsqueeze(0).to(device)\n",
    "\n",
    "        # Trích xuất embedding\n",
    "        with torch.no_grad():\n",
    "            embedding = model(input_tensor).cpu().numpy()\n",
    "\n",
    "        # Lưu embedding theo tên file\n",
    "        person_name = os.path.splitext(file_name)[0]  # Lấy tên file mà không có phần mở rộng\n",
    "        embeddings[person_name] = embedding\n",
    "\n",
    "# Lưu embeddings vào file để tái sử dụng\n",
    "np.save(\"reference_embeddings.npy\", embeddings)\n",
    "print(\"Embedding của các ảnh tham chiếu đã được lưu.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_embeddings = np.load(\"reference_embeddings.npy\", allow_pickle=True).item()\n",
    "\n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    return np.dot(embedding1, embedding2.T) / (np.linalg.norm(embedding1) * np.linalg.norm(embedding2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11131/1292669134.py:34: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  max_similarity = float(max_similarity)\n"
     ]
    }
   ],
   "source": [
    "# Mở camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Không thể truy cập camera.\")\n",
    "        break\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    box, prob = mtcnn.detect(rgb_frame)\n",
    "\n",
    "    if box is not None:\n",
    "        for (x1, y1, x2, y2) in box:\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            face = rgb_frame[y1:y2, x1:x2]  # Cắt khuôn mặt\n",
    "            face_image = Image.fromarray(face).resize((160, 160))\n",
    "\n",
    "            # Trích xuất embedding từ khuôn mặt live cam\n",
    "            input_tensor = transforms.Compose([\n",
    "                transforms.Resize((160, 160)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "            ])(face_image).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                live_embedding = model(input_tensor).cpu().numpy()\n",
    "\n",
    "            # So sánh với embedding tham chiếu\n",
    "            matched_name = \"Unknown\"\n",
    "            max_similarity = 0\n",
    "            for name, ref_embedding in reference_embeddings.items():\n",
    "                similarity = cosine_similarity(live_embedding, ref_embedding)\n",
    "                if similarity > max_similarity and similarity > 0.8:  # Ngưỡng: 0.8\n",
    "                    matched_name = name\n",
    "                    max_similarity = similarity\n",
    "            max_similarity = float(max_similarity)\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"{matched_name} ({max_similarity:.2f})\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    cv2.imshow('Live Face Recognition', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facenet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

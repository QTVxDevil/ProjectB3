{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(image_size=160, margin=0, min_face_size=20,\n",
    "              thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((160, 160)),      # Resize ảnh về 160x160\n",
    "    transforms.ToTensor(),              # Chuyển ảnh thành tensor\n",
    "    transforms.Normalize(               # Chuẩn hóa giá trị pixel\n",
    "        mean=[0.5, 0.5, 0.5], \n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Danh sách ảnh: ['Data/ac84e587-7413-11ef-bf8a-e81f155e7428.jpg', 'Data/4a00b567-e124-4b28-89f1-36d331729d12.jpg', 'Data/583448a4-aad6-11ef-b52d-c403a8a5aea1.jpg', 'Data/caebf623-1951-43ed-99e0-dd76e1c9569e.jpg', 'Data/a7b937a7-7413-11ef-b46f-e81f155e7428.jpg', 'Data/ab16ce1e-7413-11ef-a7e1-e81f155e7428.jpg', 'Data/a6a96299-7413-11ef-8665-e81f155e7428.jpg', 'Data/b09b68ad-0441-4f77-a477-1eb8c900222c.jpg', 'Data/f58342e0-cc56-429f-aa99-aca8b838899e.jpg', 'Data/579baa43-8319-4e8d-9c45-c90bd6c9c3f9.jpg']\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"Data\"\n",
    "image_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith(('.jpg', '.png'))]\n",
    "\n",
    "print(\"Danh sách ảnh:\", image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embedding(model, image_path, device):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    input_tensor = preprocess(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        embedding = model(input_tensor)\n",
    "    return embedding.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding của các ảnh tham chiếu đã được lưu.\n"
     ]
    }
   ],
   "source": [
    "embeddings = {}\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(('.jpg', '.png')):  # Chỉ lấy ảnh có đuôi .jpg hoặc .png\n",
    "        # Tải ảnh và tiền xử lý\n",
    "        image_path = os.path.join(folder_path, file_name)\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        input_tensor = preprocess(image).unsqueeze(0).to(device)\n",
    "\n",
    "        # Trích xuất embedding\n",
    "        with torch.no_grad():\n",
    "            embedding = model(input_tensor).cpu().numpy()\n",
    "\n",
    "        # Lưu embedding theo tên file\n",
    "        person_name = os.path.splitext(file_name)[0]  # Lấy tên file mà không có phần mở rộng\n",
    "        embeddings[person_name] = embedding\n",
    "\n",
    "# Lưu embeddings vào file để tái sử dụng\n",
    "np.save(\"reference_embeddings.npy\", embeddings)\n",
    "print(\"Embedding của các ảnh tham chiếu đã được lưu.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_embeddings = np.load(\"reference_embeddings.npy\", allow_pickle=True).item()\n",
    "for name, embedding in reference_embeddings.items():\n",
    "    if not isinstance(embedding, np.ndarray):  # Kiểm tra nếu không phải NumPy array\n",
    "        reference_embeddings[name] = np.array(embedding)\n",
    "\n",
    "        \n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    # Đảm bảo các embedding là NumPy array\n",
    "    if isinstance(embedding1, dict) or isinstance(embedding2, dict):\n",
    "        raise ValueError(\"Input embeddings must be NumPy arrays, not dictionaries.\")\n",
    "    if not isinstance(embedding1, np.ndarray) or not isinstance(embedding2, np.ndarray):\n",
    "        raise TypeError(\"Both embeddings must be NumPy arrays.\")\n",
    "\n",
    "    # Tính độ tương đồng cosine\n",
    "    return np.dot(embedding1, embedding2.T) / (np.linalg.norm(embedding1) * np.linalg.norm(embedding2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ảnh đã được lưu: captured_face.jpg\n",
      "Độ tương đồng: 0.68\n",
      "Khuôn mặt không khớp với ảnh tham chiếu!\n",
      "Ảnh đã được lưu: captured_face.jpg\n",
      "Độ tương đồng: 0.61\n",
      "Khuôn mặt không khớp với ảnh tham chiếu!\n"
     ]
    }
   ],
   "source": [
    "# Mở camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Không thể truy cập camera.\")\n",
    "        break\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    box, prob = mtcnn.detect(rgb_frame)\n",
    "\n",
    "    if box is not None:\n",
    "        for (x1, y1, x2, y2) in box:\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            face = rgb_frame[y1:y2, x1:x2]  # Cắt khuôn mặt\n",
    "            face_image = Image.fromarray(face).resize((160, 160))\n",
    "\n",
    "            # Trích xuất embedding từ khuôn mặt live cam\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"s\"):\n",
    "                # Lưu ảnh\n",
    "                saved_path = \"captured_face.jpg\"\n",
    "                face_image.save(saved_path)\n",
    "                print(f\"Ảnh đã được lưu: {saved_path}\")\n",
    "\n",
    "                # Tính embedding từ ảnh chụp\n",
    "                face_tensor = preprocess(face_image).unsqueeze(0).to(device)  # Xử lý ảnh\n",
    "                with torch.no_grad():\n",
    "                    face_embedding = model(face_tensor).cpu().numpy()  # Tính embedding\n",
    "\n",
    "                # So sánh với embedding tham chiếu\n",
    "                similarity = cosine_similarity(face_embedding, embedding)[0][0]\n",
    "                print(f\"Độ tương đồng: {similarity:.2f}\")\n",
    "\n",
    "                # Kiểm tra ngưỡng tương đồng\n",
    "                if similarity > 0.8:  # Ngưỡng tùy chỉnh\n",
    "                    print(\"Khuôn mặt khớp với ảnh tham chiếu!\")\n",
    "                else:\n",
    "                    print(\"Khuôn mặt không khớp với ảnh tham chiếu!\")\n",
    "    cv2.imshow('Live Face Recognition', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facenet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
